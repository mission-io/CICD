image: python:2.7

pipelines:
  branches:
    master:
      - step:
          name: Build and Containerize the App
          services:
            - docker
          trigger: manual
          script:
            - docker build -t <docker-image-name> .
  default:
    - step:
        name: Build and Containerize the App
        services:
          - docker
        caches:
          - docker
        script:
          - pip install --upgrade awscli==1.14.5 s3cmd==2.0.1 python-magic
          - aws configure set aws_access_key_id "${AWS_ACCESS_KEY_ID}"
          - aws configure set aws_secret_access_key "${AWS_SECRET_ACCESS_KEY}"
          - aws configure set region "${DEFAULT_REGION_NAME}"
          - eval $(aws ecr get-login --no-include-email --region "${DEFAULT_REGION_NAME}")
          - docker build -t <docker-image-name> .
          - docker tag <docker-image-name>:latest <aws-ecr-path>/<docker-image-name>:latest
          - docker push <aws-ecr-path>/<docker-image-name>:latest
          - aws ecs update-service --cluster <ecs-forgate-cluster-name> --service <ecs-service-name> --task-definition <ecs-task-definition-name[:version]> --force-new-deployment
definitions:
  services:
    docker:
      memory: 2048


# Reference
# 1. https://bitbucket.org/blog/automating-amazon-elastic-container-ecr-container-builds-using-bitbucket-pipelines
# 2. https://confluence.atlassian.com/bitbucket/use-services-and-databases-in-bitbucket-pipelines-874786688.html#UseservicesanddatabasesinBitbucketPipelines-Servicememorylimits
# 3. https://docs.aws.amazon.com/cli/latest/reference/ecs/update-service.html
